{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMAMKh9HV4xV0vbDTcWEkIO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Course Name: **AI Mastery Bootcamp: AI Algorithms, DeepSeek AI, AI Agents**\n","\n","# Section 18: **Advanced TensorFlow**"],"metadata":{"id":"69iTnd4N2HKO"}},{"cell_type":"markdown","source":["## Deploying TensorFlow Models\n","### Saving and Loading Models"],"metadata":{"id":"QuRt6ZMN2KJE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BlL0k4df2GUd"},"outputs":[],"source":["## 1. Saving Models\n","### 1.1. Save Entire Model\n","model.save('my_model.h5')\n","\n","### 1.2. Save Model Architecture to JSON file\n","with open('model_architecture.json', 'w') as json_file:\n","  json_file.write(model.to_json())\n","\n","### 1.3. Save Model Weights to HDF5 file\n","model.save_weights('model_weights.h5')\n","\n","### 1.4. Load Entire Model\n","from tf.keras.models import load_model\n","loaded_model= load_model('my_model.h5')\n","\n","### 1.5. Model Architecture and Weights Separately\n","from tf.keras.models import model_from_json\n","\n","with open('model_architecture.json', 'r') as json_file:\n","  loaded_model= model_from_json(json_file.read())\n","\n","### 1.6. Load Model weights from HDF5 File\n","loaded_model.load_weights('model_weights.h5')"]},{"cell_type":"markdown","source":["#### TensorFlow Serving for Model Deployment\n","\n","* **1. Installation and Setup**\n","* **1.1. Install Tensorflow Serving via Docker**\n","```docker\n","docker pull tensorflow/serving\n","```\n","\n","* **2. Exporting Tensorflow Models**\n","\n","```python\n","import tensorflow as tf\n","\n","### Example: Export a trained model to the SavedModel format\n","model= tf.keras.models.loaded_model('trained_model.h5')\n","tf.saved_model.save(model, 'saved_model')\n","```\n","\n","* **3. Running Tensorflow Serving**\n","```docker\n","docker run -p 8501:8501 --name=tensorflow_serving\\\n","  --mount type=bind,source=/path/to/saved_model,target=/models/my_model \\\n","  -e MODEL_NAME=my_model \\\n","  -t tensorflow/serving\n","```\n","\n","* **4. Serving Requests**\n","\n","```docker\n","curl -d '{'instances': [[1.0, 2.0, 3.0, 4.0]]}' \\\n","  -X POST http://localhost:8501/v1/models/my_model:predict\n","```\n","\n","* Model Versioning and Updating\n","* Monitoring and Management\n","* Scalability and Performance\n"],"metadata":{"id":"8zmFCQL12U4v"}},{"cell_type":"markdown","source":["## TensorFlow Lite for Mobile and Embedded Devices"],"metadata":{"id":"tXWUNvB22uC0"}},{"cell_type":"code","source":["## 1. Conversion to TensorFlow Lite Format\n","import tensorflow as tf\n","\n","### Load the trained Tensorflow Model\n","model= tf.keras.models.load_model('my_model.h5')\n","\n","### Convert the model to TensorFlow Lite format\n","converter= tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model= converter.convert()\n","\n","### Saved the converted Tensorflow Lite model to a file\n","with open('my_model.tflite', 'wb') as f:\n","  f.write(tflite_model)"],"metadata":{"id":"ReCGFIDd2JC-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### TensorFlow Lite Interpreter"],"metadata":{"id":"S7r3HQWe3Svv"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","\n","### Load the TensorFlow Lite model\n","interpreter= tf.lite.Interpreter(model_path='my_model.tflite')\n","\n","### Allocate tensors to the interpreter\n","interpreter.allocate_tensors()\n","\n","### Get input and output tensors\n","input_details= interpreter.get_input_details()\n","output_details= interpreter.get_output_details()\n","\n","### Prepare input data\n","input_data= np.array([[1.0, 2.0, 3.0, 4.0]], dtype=np.float32)\n","\n","### Set the input tensor\n","interpreter.set_tensor(input_details[0]['index'], input_data)\n","\n","### Run inference\n","interpreter.invoke()\n","\n","### Get the output tensor\n","output_data= interpreter.get_tensor(output_details[0]['index'])\n","\n","### Process the output\n","print(f\"Output: \", output_data)"],"metadata":{"id":"n-cPX0wA3aUB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["$$ ⇑ ⇑ ⇑ $$\n","\n","* **Model Optimization Techniques**\n","  * Quantization\n","  * Model Pruning\n","  * Operator Fusion\n","  * Selective Execution\n","* Deployment on Mobile and Embedded Devices"],"metadata":{"id":"qfL7uGM14It-"}},{"cell_type":"markdown","source":["## Distributed TensorFlow\n","### Introduction to Distributed Computing with TensorFlow\n","* Distributed TensorFlow Architecture\n","  * Worker Nodes\n","  * Parameter Server (PS)\n","  * Cluster Spec\n","* Distributed Training Strategies\n","  * Data Parallelism\n","  * Model Parallelism\n","  * Pipeline Parallelism\n","* TensorFlow's Distributed Execution\n","  * Distributed Sessions\n","  * Distributed Optimizers\n","  * Fault Tolerance\n","* Deployment and Configuration\n","  * tf.distribute.Strategy\n","  * TensorFlow Extended (TFX)\n","\n","### TensorFlow's Distributed Execution Framework\n","* Distributed Execution Engine\n","  * Distributed Sessions\n","  * Distributed Optimizers\n","  * Fault Tolerance\n","* Distributed Training Strategies\n","  * Data Parallelism\n","  * Model Parallelism\n","  * Pipeline Parallelism\n","* Deployment and Configuration\n","  * tf.distribute.Strategy\n","  * TensorFlow Extended (TFX)"],"metadata":{"id":"HdvQ5nFu4gWQ"}},{"cell_type":"markdown","source":["### Scaling TensorFlow with TensorFlow Serving and Kubernetes\n","* TensorFlow Serving\n","  * Servables\n","  * Loaders\n","  * Predictors\n","* Kubernetes\n","  * Pods\n","  * Deployments\n","  * Services\n","* Scaling TensorFlow with TensorFlow Serving and Kubernetes\n","  * Containerize TensorFlow Models\n","  * Deploy TensorFlow Serving on Kubernetes\n","  * Expose TensorFlow Serving Service\n","  * Load and Serve TensorFlow Models\n","  * Scale and Manage TensorFlow Serving Instances"],"metadata":{"id":"VL-2EEuM6Can"}},{"cell_type":"markdown","source":["## TensorFlow Extended: Introduction to TFX\n","* Key Components of TFX\n","  * TFX Pipeline\n","  * TFX Components\n","    * ExampleGen\n","    * StatisticsGen\n","    * SchemaGen\n","    * ExampleValidator\n","    * Transform\n","    * Trainer\n","    * Evaluator\n","    * Pusher\n","    * TFX Orchestration\n","    * TFX Metadata Store\n","* Features of TFX\n","  * End-to-End Automation\n","  * Scalability and Robustness\n","  * Customizability and Extensibility\n","  * Monitoring and Governance\n","* Deployment and Integration"],"metadata":{"id":"LK-_ziNZ6knQ"}},{"cell_type":"markdown","source":["## Building End-to-End ML Pipelines with TFX\n","1. Define the ML Pipeline\n","2. Data Ingestion and Preprocessing\n","3. Data Validation and Schema Inference\n","4. Model Training and Evaluation\n","5. Model Deployment\n","6. Monitoring and Governance\n","7. Orchestration and Execution"],"metadata":{"id":"98Y6qxNK7WdN"}},{"cell_type":"markdown","source":["## Model Validation, Transform, and Serving with TFX\n","1. Model Validation\n","  * Evaluator Component\n","  * Evaluation Metrics\n","  * Visualization and Analysis\n","2. Data Transformation\n","  * Transform Component\n","  * Schema Inference\n","  * Custom Transformations\n","3. Model Serving\n","  * Pusher Component\n","  * Model Versioning\n","  * Monitoring and Management"],"metadata":{"id":"taI8ATJM7pzR"}}]}