{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMKqNasoZS7pIj3tJdvvDfN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Course Name: **AI Mastery Bootcamp: AI Algorithms, DeepSeek AI, AI Agents**\n","\n","# Section 14: **Machine Learning Algorithms and Implementations**"],"metadata":{"id":"TR9OltJmq0K9"}},{"cell_type":"markdown","source":["## Supervised Machine Learning\n","\n","### Regression Algorithms\n","* Linear Regression\n","* Ridge and Lasso Regression\n","* Polynomial Regression\n","\n","### Classification Algorithms\n","* Logistic Regression\n","* K-Nearest Neighbors (KNN)\n","* Support Vector Machines (SVM)\n","* Decision Tree\n","* Random Forest\n","* Gradient Descent\n","* Naive Bayes\n","\n","## Unsupervised Machine Learning\n","\n","### Clustering Algorithms\n","* K-Means Clustering\n","* Hierarchical Clustering\n","* DBSCAN (Density-Based Spatial Clustering of Application with Noise)\n","* Gaussian Mixture Models (GMM)\n","\n","### Dimensionality Reduction Algorithms\n","* Principal Component Analysis (PCA)\n","* t-Distributed Stochastic Neighbor Embedding (t-SNE)\n","* Autoencoders\n","\n","## Other Specialized Categories\n","\n","### Semi-Supervised Learning\n","* Self-Training\n","\n","### Reinforcement Learning\n","* Q-Learning\n","* Deep Q-Networks (DQN)\n","* Policy Gradient Methods\n","\n","### Anomaly Detection Algorithms\n","* One-Class SVM\n","* Isolation Forest\n","\n","### Neural Networks (Deep Learning)\n","* Convolutional Neural Networks (CNNs)\n","* Recurrent Neural Networks (RNNs)\n","* Long Short-Term Memory (LSTM)\n","* Transformers"],"metadata":{"id":"DkyjYjqVrBMY"}},{"cell_type":"markdown","source":["## Linear Regression\n","Linear Regression is a supervised learning algorithm used\n","for predicting a continuous target variable based on one or\n","more input features. It finds the line of best fit (linear\n","relationship) by minimizing the sum of squared differences\n","between the actual and predicted values."],"metadata":{"id":"ROpjQ3NauT8R"}},{"cell_type":"code","source":["# Import necessary libraries\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","import numpy as np"],"metadata":{"id":"Hn2-OyBGuTJ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uTAD3opvqyuQ","executionInfo":{"status":"ok","timestamp":1740934236019,"user_tz":-330,"elapsed":67,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"1a60abd1-bcf6-4eda-adb2-12994ad8ce31"},"outputs":[{"output_type":"stream","name":"stdout","text":["MSE : 4973274832.886891\n","Predicted Values  [235246.09018111 257853.60348256]\n"]}],"source":["# Sample Data (e.g. ::house size, house price)\n","X= np.array([[1400], [1600], [1700], [1875], [1100], [1550], [2350], [2450], [1425], [1700]])\n","y= np.array([245000, 312000, 279000, 308000, 199000, 219000, 405000, 324000, 319000, 255000])\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.2, random_state= 42)\n","\n","# Initialize and train the model\n","model= LinearRegression()\n","model.fit(X_train, y_train)\n","\n","# Make predictions\n","y_pred= model.predict(X_test)\n","\n","# Evaluate the model\n","mse= mean_squared_error(y_test, y_pred)\n","print(\"MSE :\", mse)\n","print(\"Predicted Values \", y_pred)"]},{"cell_type":"markdown","source":["## Ridge and Lasso Regression\n","Ridge and Lasso Regression are regularization techniques applied to Linear Regression to prevent overfitting by penalizing large coefficients:\n","* Ridge Regression adds an L2 penalty (sum of squared coefficients).\n","* Lasso Regression adds an Ll penalty (sum of absolute values of coefficients), which can lead to feature selection by shrinking some coefficients to zero."],"metadata":{"id":"mm_KALLExVzF"}},{"cell_type":"code","source":["# Import necessary libraries\n","from sklearn.linear_model import Ridge, Lasso\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","import numpy as np"],"metadata":{"id":"CQcOmtJBq9K1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sample Data (e.g. ::house size, house price)\n","X= np.array([[1400], [1600], [1700], [1875], [1100], [1550], [2350], [2450], [1425], [1700]])\n","y= np.array([245000, 312000, 279000, 308000, 199000, 219000, 405000, 324000, 319000, 255000])\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.2, random_state= 42)\n","\n","print(\"*\"*10, \"Ridge Model\", \"*\"*10)\n","# Ridge Model\n","ridge_model= Ridge(alpha= 0.1)\n","ridge_model.fit(X_train, y_train)\n","\n","# Make predictions\n","ridge_pred= ridge_model.predict(X_test)\n","\n","# Evaluate the model\n","ridge_mse= mean_squared_error(y_test, ridge_pred)\n","print(\"Ridge MSE :\", ridge_mse)\n","print(\"Ridge Predicted Values \", ridge_pred)\n","\n","print(\"=\"*100)\n","\n","print(\"*\"*10, \"Lasso Model\", \"*\"*10)\n","# Lasso Model\n","lasso_model= Lasso(alpha= 0.1)\n","lasso_model.fit(X_train, y_train)\n","\n","# Make predictions\n","lasso_pred= lasso_model.predict(X_test)\n","\n","# Evaluate the model\n","lasso_mse= mean_squared_error(y_test, lasso_pred)\n","print(\"Lasso MSE :\", lasso_mse)\n","print(\"Lasso Predicted Values \", lasso_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n9I8p3cwxzxb","executionInfo":{"status":"ok","timestamp":1740934830614,"user_tz":-330,"elapsed":19,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"0fc234f3-30ad-4a9d-b932-07453e64aed2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["********** Ridge Model **********\n","Ridge MSE : 4973274499.659226\n","Ridge Predicted Values  [235246.0932082  257853.60495445]\n","====================================================================================================\n","********** Lasso Model **********\n","Lasso MSE : 4973274812.251329\n","Lasso Predicted Values  [235246.09036857 257853.60357371]\n"]}]},{"cell_type":"markdown","source":["## Polynomial Regression\n","Polynomial Regression is an extension of Linear Regression that models the relationship between the input features and the target variable as an nth-degree polynomial. It can capture non-linear relationships in the data by adding polynomial terms to the features."],"metadata":{"id":"_VUZH4LrzbUE"}},{"cell_type":"code","source":["# Import necessary libraries\n","from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","import numpy as np"],"metadata":{"id":"2bAvIYbjzSRi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sample data (e.g.:: Experience VS Salary)\n","X= np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]])\n","y= np.array([45000, 50000, 60000, 80000, 110000, 150000, 200000, 200000, 400000, 500000])\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.2, random_state= 42)\n","\n","# Transform features into ploynomial features Ploynomial Model\n","poly= PolynomialFeatures(degree= 2)\n","\n","X_train_poly= poly.fit_transform(X_train)\n","X_test_poly= poly.transform(X_test)\n","\n","# Initialize and train the model\n","model= LinearRegression()\n","model.fit(X_train_poly, y_train)\n","\n","# Make predictions\n","y_pred= model.predict(X_test_poly)\n","\n","# Evaluate the model\n","mse= mean_squared_error(y_test, y_pred)\n","print(\"Polynomial Model: MSE :\", mse)\n","print(\"Predicted Values \", y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WVSWNhEdz5wh","executionInfo":{"status":"ok","timestamp":1740935450565,"user_tz":-330,"elapsed":20,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"25ab43b0-c1e6-4b08-9c6b-be1708398583"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Polynomial Model: MSE : 730764608.9978654\n","Predicted Values  [361807.16506501  48315.78575466]\n"]}]},{"cell_type":"markdown","source":["## Logistic Regression\n","Logistic Regression is a supervised learning algorithm used for binary classification problems (e.g., yes/no, spam/not spam).\n","\n","Instead of predicting a continuous output, it predicts the probability of an observation belonging to a particular class by applying the logistic (sigmoid) function, which outputs values between 0 and 1."],"metadata":{"id":"5fwSnOG71xv5"}},{"cell_type":"code","source":["# Import necessary libraries\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","import numpy as np"],"metadata":{"id":"JVxlAZ0d1kE3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sample data (e.g.:: hours studied VS pass/fail)\n","X= np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]])\n","y= np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.2, random_state= 42)\n","\n","# Initialize and train the model\n","model= LogisticRegression()\n","model.fit(X_train, y_train)\n","\n","# Make predictions\n","y_pred= model.predict(X_test)\n","\n","# Evaluate the model\n","accuracy= accuracy_score(y_test, y_pred)\n","conf_matrix= confusion_matrix(y_test, y_pred)\n","\n","print(\"Accuracy :\", accuracy)\n","print(\"Confusion Matrix: \\n \", conf_matrix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-9fZNnAB2Geu","executionInfo":{"status":"ok","timestamp":1740935840406,"user_tz":-330,"elapsed":15,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"a1d54aab-464a-4305-fd71-f47302f5f4c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy : 1.0\n","Confusion Matrix: \n","  [[1 0]\n"," [0 1]]\n"]}]},{"cell_type":"markdown","source":["## K-Nearest Neighbors (KNN)\n","K-Nearest Neighbors (KNN) is a simple, non-parametric classification (or regression) algorithm. It classifies new data points based on the majority class of the k-nearest points in the feature space. It's particularly useful for smaller datasets where the relationships among data points can be easily visualized."],"metadata":{"id":"O4-m15wC3QoF"}},{"cell_type":"code","source":["# Import necessary libraries\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","import numpy as np"],"metadata":{"id":"go7oQHZg2goK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sample data (e.g.:: hours studied and prior grades VS pass/fail)\n","X= np.array([[1, 50], [2, 60], [3, 55], [4, 65], [5, 70], [6, 75], [7, 80], [8, 90], [9, 95], [10, 100]])\n","y= np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.2, random_state= 42)\n","\n","# Initialize and train the model with k= 3\n","model= KNeighborsClassifier(n_neighbors=3)\n","model.fit(X_train, y_train)\n","\n","# Make predictions\n","y_pred= model.predict(X_test)\n","\n","# Evaluate the model\n","accuracy= accuracy_score(y_test, y_pred)\n","conf_matrix= confusion_matrix(y_test, y_pred)\n","\n","print(\"Accuracy :\", accuracy)\n","print(\"Confusion Matrix: \\n \", conf_matrix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GIKzTWGz3tS-","executionInfo":{"status":"ok","timestamp":1740936100333,"user_tz":-330,"elapsed":24,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"f2f75dc8-eb83-4036-8202-09602a0f8661"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy : 1.0\n","Confusion Matrix: \n","  [[1 0]\n"," [0 1]]\n"]}]},{"cell_type":"markdown","source":["## Support Vector Machines (SVM)\n","Support Vector Machines (SVM) is a powerful classification algorithm that works by finding the hyperplane that best separates classes in the feature space. SVM aims to maximize the margin between the classes, making it a good choice for binary classification, especially when classes are well-separated."],"metadata":{"id":"-DWrRBS74qty"}},{"cell_type":"code","source":["# Import necessary libraries\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","import numpy as np"],"metadata":{"id":"khwRAodC4FDS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sample data (e.g.:: hours studied and prior grades VS pass/fail)\n","X= np.array([[1, 50], [2, 60], [3, 55], [4, 65], [5, 70], [6, 75], [7, 80], [8, 90], [9, 95], [10, 100]])\n","y= np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.2, random_state= 42)\n","\n","# Initialize and train the model\n","model= SVC(kernel= \"linear\")\n","model.fit(X_train, y_train)\n","\n","# Make predictions\n","y_pred= model.predict(X_test)\n","\n","# Evaluate the model\n","accuracy= accuracy_score(y_test, y_pred)\n","conf_matrix= confusion_matrix(y_test, y_pred)\n","\n","print(\"Accuracy :\", accuracy)\n","print(\"Confusion Matrix: \\n \", conf_matrix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xJU8vxe64zwc","executionInfo":{"status":"ok","timestamp":1740936296445,"user_tz":-330,"elapsed":40,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"e957393c-9816-4a48-ab92-292e6c047006"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy : 1.0\n","Confusion Matrix: \n","  [[1 0]\n"," [0 1]]\n"]}]},{"cell_type":"markdown","source":["## Decision Trees\n","Decision Trees are a versatile supervised learning algorithm used for both classification and regression. They work by recursively splitting the data into subsets based on the feature that provides the most information gain. Each node represents a decision based on a feature, and each leaf node represents a prediction."],"metadata":{"id":"kFuhPJNE5CUE"}},{"cell_type":"code","source":["# Import necessary libraries\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","import numpy as np\n","\n","# Sample data (e.g.:: hours studied and prior grades VS pass/fail)\n","X= np.array([[1, 50], [2, 60], [3, 55], [4, 65], [5, 70], [6, 75], [7, 80], [8, 90], [9, 95], [10, 100]])\n","y= np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.2, random_state= 42)\n","\n","# Initialize and train the model\n","model= DecisionTreeClassifier()\n","model.fit(X_train, y_train)\n","\n","# Make predictions\n","y_pred= model.predict(X_test)\n","\n","# Evaluate the model\n","accuracy= accuracy_score(y_test, y_pred)\n","conf_matrix= confusion_matrix(y_test, y_pred)\n","\n","print(\"Accuracy :\", accuracy)\n","print(\"Confusion Matrix: \\n \", conf_matrix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7pxAuQSG47ZY","executionInfo":{"status":"ok","timestamp":1740936372629,"user_tz":-330,"elapsed":16,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"771e6501-1e0d-478b-f922-8605055f425e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy : 1.0\n","Confusion Matrix: \n","  [[1 0]\n"," [0 1]]\n"]}]},{"cell_type":"markdown","source":["## Random Forests\n","Random Forests are an ensemble learning method that combines multiple decision trees to make a more accurate and stable prediction. Each tree in the forest is trained on a random subset of the data, and the final prediction is made by averaging (for regression) or voting (for classification) the predictions of individual trees. This helps to reduce overfitting and improve generalization."],"metadata":{"id":"VsP_gmtK5bUo"}},{"cell_type":"code","source":["# Import necessary libraries\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","import numpy as np\n","\n","# Sample data (e.g.:: hours studied and prior grades VS pass/fail)\n","X= np.array([[1, 50], [2, 60], [3, 55], [4, 65], [5, 70], [6, 75], [7, 80], [8, 90], [9, 95], [10, 100]])\n","y= np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.2, random_state= 42)\n","\n","# Initialize and train the model\n","model= RandomForestClassifier(n_estimators=100, random_state=42)\n","model.fit(X_train, y_train)\n","\n","# Make predictions\n","y_pred= model.predict(X_test)\n","\n","# Evaluate the model\n","accuracy= accuracy_score(y_test, y_pred)\n","conf_matrix= confusion_matrix(y_test, y_pred)\n","\n","print(\"Accuracy :\", accuracy)\n","print(\"Confusion Matrix: \\n \", conf_matrix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DdwrXI0P5OAN","executionInfo":{"status":"ok","timestamp":1740936488063,"user_tz":-330,"elapsed":91,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"d6448b30-1391-4931-83a8-97051cf167fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy : 1.0\n","Confusion Matrix: \n","  [[1 0]\n"," [0 1]]\n"]}]},{"cell_type":"markdown","source":["## Gradient Boosting\n","Gradient Boosting is an ensemble technique that builds a series of decision trees, where each tree corrects the errors of the previous ones. By combining the predictions of these trees, Gradient Boosting models create a more accurate final prediction. Popular implementations include XGBoost, LightGBM, and CatBoost, which are optimized for speed and accuracy."],"metadata":{"id":"E_3LPa855waJ"}},{"cell_type":"code","source":["# Import necessary libraries\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","import numpy as np\n","\n","# Sample data (e.g.:: hours studied and prior grades VS pass/fail)\n","X= np.array([[1, 50], [2, 60], [3, 55], [4, 65], [5, 70], [6, 75], [7, 80], [8, 90], [9, 95], [10, 100]])\n","y= np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.2, random_state= 42)\n","\n","# Initialize and train the model\n","model= GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n","model.fit(X_train, y_train)\n","\n","# Make predictions\n","y_pred= model.predict(X_test)\n","\n","# Evaluate the model\n","accuracy= accuracy_score(y_test, y_pred)\n","conf_matrix= confusion_matrix(y_test, y_pred)\n","\n","print(\"Accuracy :\", accuracy)\n","print(\"Confusion Matrix: \\n \", conf_matrix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Il_gzWlf5ktO","executionInfo":{"status":"ok","timestamp":1740936598677,"user_tz":-330,"elapsed":131,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"89947344-d070-45ec-f9e4-cd9811943673"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy : 1.0\n","Confusion Matrix: \n","  [[1 0]\n"," [0 1]]\n"]}]},{"cell_type":"markdown","source":["## Naive Bayes\n","Naive Bayes is a probabilistic classifier based on Bayes' theorem, which assumes that the features are conditionally independent given the class label. Despite this \"naive\" assumption, it often performs well in text classification and spam detection tasks."],"metadata":{"id":"EBNTN0kZ6KBP"}},{"cell_type":"code","source":["# Import necessary libraries\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","import numpy as np\n","\n","# Sample data (e.g.:: hours studied and prior grades VS pass/fail)\n","X= np.array([[1, 50], [2, 60], [3, 55], [4, 65], [5, 70], [6, 75], [7, 80], [8, 90], [9, 95], [10, 100]])\n","y= np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.2, random_state= 42)\n","\n","# Initialize and train the model\n","model= GaussianNB()\n","model.fit(X_train, y_train)\n","\n","# Make predictions\n","y_pred= model.predict(X_test)\n","\n","# Evaluate the model\n","accuracy= accuracy_score(y_test, y_pred)\n","conf_matrix= confusion_matrix(y_test, y_pred)\n","\n","print(\"Accuracy :\", accuracy)\n","print(\"Confusion Matrix: \\n \", conf_matrix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"35hch2D-6FIy","executionInfo":{"status":"ok","timestamp":1740936661780,"user_tz":-330,"elapsed":22,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"8b914f9a-940e-4f72-b172-654d28a2ccec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy : 1.0\n","Confusion Matrix: \n","  [[1 0]\n"," [0 1]]\n"]}]},{"cell_type":"markdown","source":["## K-Means Clustering\n","K-Means Clustering is an unsupervised learning algorithm that partitions data into k clusters. Each cluster is defined by its centroid, and each data point is assigned to the nearest cluster.\n","\n","The algorithm iteratively adjusts centroids to minimize the variance within each cluster."],"metadata":{"id":"cUy_UBlG6a8t"}},{"cell_type":"code","source":["# Import necessary libraries\n","from sklearn.cluster import KMeans\n","import numpy as np\n","\n","# Sample data (e.g.:: hours studied and prior grades VS pass/fail)\n","X= np.array([[1, 2], [1, 4], [1, 0],\n","            [10, 2], [10, 4], [10, 0]])\n","\n","# Initialize and fit the model\n","kmeans= KMeans(n_clusters=2, random_state=42)\n","kmeans.fit(X)\n","\n","# Get the cluster centers ad labels\n","centroids= kmeans.cluster_centers_\n","labels= kmeans.labels_\n","\n","print(\"Cluster Centers: \\n \", centroids)\n","print(\"Labels :\", labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xeyMTREs6Ul6","executionInfo":{"status":"ok","timestamp":1740937021032,"user_tz":-330,"elapsed":85,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"3131fac5-ccf7-4f44-af9e-0ddc4294d81b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cluster Centers: \n","  [[ 1.  2.]\n"," [10.  2.]]\n","Labels : [0 0 0 1 1 1]\n"]}]},{"cell_type":"markdown","source":["## Hierarchical Clustering\n","Hierarchical Clustering is an unsupervised learning algorithm that builds a hierarchy of clusters. It starts with each data point as its own cluster and then merges or splits clusters based on distance measures, forming a tree-like structure called a dendrogram. The hierarchy can be used to choose a suitable number of clusters by \"cutting\" the tree at a specific level."],"metadata":{"id":"slZlk5Q-7wjN"}},{"cell_type":"code","source":["# Import necessary libraries\n","from scipy.cluster.hierarchy import dendrogram, linkage\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Sample data (e.g.:: hours studied and prior grades VS pass/fail)\n","X= np.array([[1, 2], [1, 4], [1, 0],\n","            [10, 2], [10, 4], [10, 0]])\n","\n","# Perform hierarchical/agglomerative clustering\n","Z = linkage(X, method= 'ward') # 'ward' minimizes variance within clusters\n","\n","# Plot dendrogram\n","plt.figure(figsize=(8, 4))\n","dendrogram(Z)\n","plt.title(\"Dendrogram for Hierarchical Clustering\")\n","plt.xlabel(\"Data Points\")\n","plt.ylabel( \"Distance\" )\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":414},"id":"3bAt79m97sSO","executionInfo":{"status":"ok","timestamp":1740937226405,"user_tz":-330,"elapsed":455,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"4acbad46-78fe-4acb-eb04-01413792c580"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 800x400 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## DBSCAN\n","DBSCAN is an unsupervised clustering algorithm that groups data points based on density, making it particularly effective for identifying clusters of arbitrary shapes and for handling noise (outliers). DBSCAN requires two parameters: eps (the maximum distance between two points to be considered neighbors) and min—samples (the minimum number of points required to form a dense region)."],"metadata":{"id":"zQZTGxo08lhs"}},{"cell_type":"code","source":["# Import necessary libraries\n","from sklearn.cluster import DBSCAN\n","import numpy as np\n","\n","# Sample data (e.g., points in 2D space)\n","X= np.array([[1, 2], [2, 2], [2, 3], [8, 7], [8, 8], [25, 80]])\n","\n","# Initialize and fit the model\n","dbscan= DBSCAN(eps=3, min_samples=2)\n","dbscan.fit(X)\n","\n","# Get the labels (-1 indicates noise)\n","labels= dbscan.labels_\n","print(\"Labels :\", labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ztORkJ6U8eND","executionInfo":{"status":"ok","timestamp":1740937527480,"user_tz":-330,"elapsed":84,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"7cfff2dc-081c-420a-d682-2f62543bc1eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Labels : [ 0  0  0  1  1 -1]\n"]}]},{"cell_type":"markdown","source":["## Gaussian Mixture Models (GMM)\n","Gaussian Mixture Models (GMM) is a probabilistic clustering algorithm that assumes data points are generated from a mixture of several Gaussian distributions with unknown parameters. GMM assigns a probability to each data point for belonging to each cluster, making it a soft clustering technique.\n","\n","It is particularly useful when clusters have different shapes or densities."],"metadata":{"id":"0cxhKV1V9sZo"}},{"cell_type":"code","source":["from sklearn.mixture import GaussianMixture\n","import numpy as np\n","\n","# Sample data (e.g., points in 2D space)\n","X= np.array([[1, 2], [2, 2], [2, 3], [8, 7], [8, 8], [25, 80]])\n","\n","# Initialize and fit the model\n","gmm = GaussianMixture(n_components=2, random_state=42)\n","gmm.fit(X)\n","\n","# Get the cluster labels and probabilities\n","labels= gmm.predict(X)\n","probs= gmm.predict_proba(X)\n","\n","print(\"Cluster Labels: \", labels)\n","print(\"Cluster Probabilities : \\n\", probs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lNY9FWvQ-IOa","executionInfo":{"status":"ok","timestamp":1740937800449,"user_tz":-330,"elapsed":37,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"db5123be-45ac-40f1-fcab-79cd5bb75321"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cluster Labels:  [0 0 0 0 0 1]\n","Cluster Probabilities : \n"," [[1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [0. 1.]]\n"]}]},{"cell_type":"markdown","source":["## Principal Component Analysis (PCA)\n","Principal Component Analysis (PCA) is a dimensionality reduction technique used to transform a high-dimensional dataset into a lower-dimensional one by identifying the directions (principal components) that capture the maximum variance in the data. PCA is widely used for data visualization, noise reduction, and speeding up machine learning algorithms by reducing the number of features."],"metadata":{"id":"3Hmf4q0J-05Q"}},{"cell_type":"code","source":["# Import necessary libraries\n","from sklearn.decomposition import PCA\n","import numpy as np\n","\n","# Sample data (e.g.,points in 3D space)\n","X= np.array([[1, 2, 3], [2, 3, 4], [3, 4, 5], [5, 6, 7], [5, 7, 8]])\n","\n","# Initialize and fit the model\n","pca = PCA(n_components=2) # Reducing to 2\n","X_reduced= pca.fit_transform(X)\n","\n","print(\"Reduced Data: \\n\", X_reduced)\n","print(\"Explained Variance Ration: \", pca.explained_variance_ratio_)"],"metadata":{"id":"h77AiagU-qlN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740986605700,"user_tz":-330,"elapsed":3333,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"0fe92a91-45c1-4fe1-cb1c-df48f9e1923d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Reduced Data: \n"," [[-4.04284848e+00 -1.24000564e-01]\n"," [-2.31516714e+00 -1.04859727e-03]\n"," [-5.87485803e-01  1.21903370e-01]\n"," [ 2.86787688e+00  3.67807304e-01]\n"," [ 4.07762455e+00 -3.64661512e-01]]\n","Explained Variance Ration:  [0.99367589 0.00632411]\n"]}]},{"cell_type":"markdown","source":["## t-Distributed Stochastic Neighbor Embedding (t-SNE)\n","t-SNE is a dimensionality reduction technique primarily used for visualizing high-dimensional data in 2D or 3D space. Unlike PCA, t-SNE is non-linear and focuses on preserving the local structure of data, making it highly effective for visualizing clusters. However, it is computationally intensive and best suited for small to medium-sized datasets."],"metadata":{"id":"Tprz847m47qQ"}},{"cell_type":"code","source":["# Import necessary libraries\n","from sklearn.manifold import TSNE\n","import numpy as np\n","\n","# Sample data (e.g.,points in 3D space)\n","X= np.array([[1, 2, 3], [2, 3, 4], [3, 4, 5], [5, 6, 7], [5, 7, 8]])\n","\n","# Initialize and fit the model\n","tsne = TSNE(n_components=2, perplexity=4, random_state=42) # Reducing to 2\n","X_reduced= tsne.fit_transform(X)\n","\n","print(\"Reduced Data: \\n\", X_reduced)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ubrlsm7G4yYc","executionInfo":{"status":"ok","timestamp":1740986913139,"user_tz":-330,"elapsed":215,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"19a53a5d-9624-41e9-f0bc-c9d1d1cfef67"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Reduced Data: \n"," [[ -70.805725   116.797104 ]\n"," [  -3.0400589 -112.191025 ]\n"," [-148.22937    -31.708574 ]\n"," [  80.70298     35.771767 ]\n"," [ -33.533886     3.501741 ]]\n"]}]},{"cell_type":"markdown","source":["## Autoencoders\n","Autoencoders are neural networks used for unsupervised learning, specifically for dimensionality reduction and feature extraction. They work by encoding input data into a compressed (latent) representation and then reconstructing the original input from this representation. Autoencoders are useful for tasks like denoising, anomaly detection, and pretraining for other neural networks."],"metadata":{"id":"--aDu--M6ES1"}},{"cell_type":"code","source":["# Import necessary libraries\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense\n","import numpy as np\n","\n","# Sample data (e.g., points in 5-Dimensionall Space)\n","X= np.array([[1, 2, 3, 4, 5], [2, 3, 4, 5, 6], [3, 4, 5, 6, 7],\n","            [5, 6, 7, 8, 9], [6, 7, 8, 9, 10], [7, 8, 9, 10, 11]])\n","\n","# Define the autoencoder model\n","input_dim= X.shape[1]\n","encoding_dim= 2 # Compressing to 2 dimensions\n","\n","# Encoder\n","input_layer= Input(shape= (input_dim,))\n","encoded= Dense(encoding_dim, activation= 'relu')(input_layer)\n","\n","# Decoder\n","decoder= Dense(input_dim, activation= 'sigmoid')(encoded)\n","\n","# Autoencoder model\n","autoencoder= Model(input_layer, decoder)\n","\n","# Compile the model\n","autoencoder.compile(optimizer= 'adam', loss= 'mse')\n","\n","# Train the model\n","autoencoder.fit(X, X, epochs=100, batch_size= 2, verbose=0)\n","\n","# Get the encoded (compressed) representation\n","encoder= Model(input_layer, encoded)\n","X_compressed= encoder.predict(X)\n","\n","print(\"Compressed Representation: \\n\", X_compressed)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UhM8MBal5tDt","executionInfo":{"status":"ok","timestamp":1740987673733,"user_tz":-330,"elapsed":7520,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"9f0a3a47-2857-49ac-ba38-6007f00ba93f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n","Compressed Representation: \n"," [[2.7118309  0.64445084]\n"," [3.808407   1.0015173 ]\n"," [4.904981   1.3585843 ]\n"," [7.0981326  2.0727174 ]\n"," [8.194707   2.4297836 ]\n"," [9.291283   2.786851  ]]\n"]}]},{"cell_type":"markdown","source":["## Self-Training\n","Self-Training is a semi-supervised learning approach that leverages a small labeled dataset alongside a larger unlabeled dataset. The model is initially trained on labeled data, and then it makes predictions on the unlabeled data. The confident predictions (those with high certainty) are then added to the labeled dataset, and the process is repeated to improve the model."],"metadata":{"id":"lHNo_n9V9IdN"}},{"cell_type":"code","source":["# Import necessary libraries\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","import numpy as np\n","\n","# Generate a synthetic dataset\n","X, y = make_classification(n_samples=200, n_features=5, random_state=42)\n","X_labeled, X_unlabeled, y_labeled, _ = train_test_split(X, y, test_size=0.7, random_state=42)\n","\n","# Initialize and train the model with labeled data\n","model = RandomForestClassifier(random_state=42)\n","model.fit(X_labeled, y_labeled)\n","\n","# Perform self-training on unlabeled data\n","for _ in range(5):  # Repeat the process 5 times for iterative training\n","    # Predict probabilities on the unlabeled data\n","    probs = model.predict_proba(X_unlabeled)\n","    high_confidence_idx = np.where(np.max(probs, axis=1) > 0.9)[0]\n","\n","    if high_confidence_idx.size == 0:\n","        # If no high confidence samples are found, stop the self-training process\n","        print(\"No high confidence samples found in this iteration.\")\n","        break\n","\n","    # Add high confidence predictions to labeled data\n","    X_labeled = np.vstack([X_labeled, X_unlabeled[high_confidence_idx]])\n","    y_labeled = np.hstack([y_labeled, model.predict(X_unlabeled[high_confidence_idx])])\n","\n","    # Remove confident samples from the unlabeled dataset\n","    X_unlabeled = np.delete(X_unlabeled, high_confidence_idx, axis=0)\n","\n","    # Retrain the model on the expanded labeled dataset\n","    model.fit(X_labeled, y_labeled)\n","\n","# Final Evaluation on a test set\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","model.fit(X_train, y_train)\n","y_pred = model.predict(X_test)\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","\n","print(\"Accuracy:\", accuracy)\n","print(\"Confusion Matrix:\\n\", conf_matrix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-aCJHr4I_EHu","executionInfo":{"status":"ok","timestamp":1740988808820,"user_tz":-330,"elapsed":1704,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"4b018d2e-ab0c-4cbf-c8cc-82009c67ee05"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["No high confidence samples found in this iteration.\n","Accuracy: 0.8833333333333333\n","Confusion Matrix:\n"," [[27  5]\n"," [ 2 26]]\n"]}]},{"cell_type":"markdown","source":["## Q-Learning\n","Q-Learning is a model-free reinforcement learning algorithm used to find the optimal action-selection policy for a given problem. It learns by interacting with an environment, updating a Q-table (a matrix of state-action values), and maximizing the expected cumulative reward. Q-Learning is effective in problems where the environment can be represented by discrete states and actions."],"metadata":{"id":"BqWWjAdgBa_p"}},{"cell_type":"code","source":["# Import necessary libraries\n","import numpy as np\n","import random\n","\n","# Define the environment (4x4 grid)\n","num_states = 16  # 4x4 grid\n","num_actions = 4  # Up, Right, Down, Left\n","q_table = np.zeros((num_states, num_actions))\n","\n","# Define the parameters\n","alpha = 0.1              # Learning Rate\n","gamma = 0.9              # Discount Factor\n","epsilon = 0.2            # Exploration Rate\n","num_episodes = 1000\n","\n","# Define a sample reward structure\n","rewards = np.zeros(num_states)\n","rewards[15] = 1  # Goal state with a reward\n","\n","# Function to determine the next state based on the action\n","def get_next_state(state, action):\n","    if action == 0 and state >= 4:                 # Up\n","        return state - 4\n","    elif action == 1 and (state + 1) % 4 != 0:     # Right\n","        return state + 1\n","    elif action == 2 and state < 12:               # Down\n","        return state + 4\n","    elif action == 3 and state % 4 != 0:           # Left\n","        return state - 1\n","    else:\n","        return state                               # If action goes out of bounds, remain in the same state\n","\n","# Q-Learning Algorithm\n","for episode in range(num_episodes):\n","    state = random.randint(0, num_states - 1)  # Start from a random state\n","    while state != 15:                         # Loop until reaching the goal state\n","        if random.uniform(0, 1) < epsilon:\n","            action = random.randint(0, num_actions - 1)  # Random Action\n","        else:\n","            action = np.argmax(q_table[state])           # Best known action\n","\n","        next_state = get_next_state(state, action)       # Get the resulting state\n","        reward = rewards[next_state]                     # Get the reward for the next state\n","        old_value = q_table[state, action]               # Current Q-value\n","        next_max = np.max(q_table[next_state])           # Max Q-value for the next state\n","\n","        # Q-Learning update rule\n","        new_value = old_value + alpha * (reward + gamma * next_max - old_value)\n","        q_table[state, action] = new_value\n","\n","        # Move to the next state\n","        state = next_state\n","\n","# Display the learned Q-Table\n","print(\"Learned Q-Table:\")\n","print(q_table)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g-rNL6SNBPZD","executionInfo":{"status":"ok","timestamp":1740990110534,"user_tz":-330,"elapsed":396,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"a09ffcf8-f296-4cf6-b4ab-0018f408472d"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Learned Q-Table:\n","[[0.16016792 0.59023364 0.27650873 0.21574442]\n"," [0.44419872 0.24704824 0.6561     0.33606408]\n"," [0.28585389 0.23579037 0.59048956 0.36495046]\n"," [0.23273477 0.04365908 0.18406013 0.53065303]\n"," [0.33456069 0.6561     0.29231549 0.24181003]\n"," [0.5856709  0.58337852 0.729      0.58833863]\n"," [0.48668643 0.4242411  0.54310963 0.6561    ]\n"," [0.2667693  0.31137685 0.25921653 0.59048723]\n"," [0.5904721  0.37957831 0.25095188 0.18372402]\n"," [0.65135965 0.64062887 0.81       0.5239607 ]\n"," [0.59048769 0.13814272 0.88669718 0.4151894 ]\n"," [0.52903188 0.07175329 0.40951    0.08036775]\n"," [0.23632739 0.80999073 0.4428289  0.25947601]\n"," [0.72796952 0.9        0.80718199 0.72084942]\n"," [0.64548539 1.         0.89892803 0.8069639 ]\n"," [0.         0.         0.         0.        ]]\n"]}]},{"cell_type":"markdown","source":["## Deep Q-Networks (DQN)\n","Deep Q-Networks (DQN) is a reinforcement learning algorithm that combines Q-Learning with deep neural networks. It uses a neural network to approximate the Q-values for each action in a given state, allowing it to handle environments with high-dimensional and continuous state spaces. DQN uses experience replay (storing past experiences and training on random batches) and a target network to stabilize training."],"metadata":{"id":"6Un1OK9fYDt_"}},{"cell_type":"code","source":["# Import necessary libraries\n","from os import truncate\n","import gym\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import random\n","\n","# Define the DQN model\n","class DQN(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super(DQN, self).__init__()\n","        self.linear1 = nn.Linear(input_size, 64)\n","        self.linear2 = nn.Linear(64, 32)\n","        self.linear3 = nn.Linear(32, output_size)\n","\n","    def forward(self, x):\n","        x = torch.relu(self.linear1(x))\n","        x = torch.relu(self.linear2(x))\n","        return self.linear3(x)\n","\n","# Hyperparameters\n","env_name = 'CartPole-v1'\n","learning_rate = 0.001\n","gamma = 0.99\n","buffer_size = 10000\n","batch_size = 32\n","epsilon = 0.1\n","target_update_frequency = 100\n","\n","# Initialize environment and DQN\n","env = gym.make(env_name)\n","input_size = env.observation_space.shape[0]\n","output_size = env.action_space.n\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","policy_net = DQN(input_size, output_size).to(device)\n","target_net = DQN(input_size, output_size).to(device)\n","target_net.load_state_dict(policy_net.state_dict())\n","target_net.eval()\n","\n","optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate)\n","criterion = nn.MSELoss()\n","\n","# Experience replay buffer\n","replay_buffer = []\n","\n","def train(num_episodes):\n","    step_count = 0  # Initialize step counter\n","\n","    for episode in range(num_episodes):\n","        state = env.reset()\n","        state = np.array(state) # Ensure `state` is a numpy array\n","\n","        done = False\n","        total_reward = 0\n","\n","        while not done:\n","            # Epsilon-greedy action selection\n","            if random.random() < epsilon:\n","                action = env.action_space.sample() # Exploration\n","            else:\n","                with torch.no_grad():\n","                    action = policy_net(torch.tensor(state, dtype=torch.float, device=device)).argmax().item()\n","\n","            # Take action and observe reward and next state\n","            next_state, reward, done, _ = env.step(action)\n","            total_reward += reward\n","\n","            # Store experience in replay buffer\n","            replay_buffer.append((state, action, reward, next_state, done))\n","            if len(replay_buffer) > buffer_size:\n","                replay_buffer.pop(0)\n","\n","            # Update current state\n","            state = next_state\n","\n","            # Sample a batch from the replay buffer\n","            if len(replay_buffer) >= batch_size:\n","                batch = random.sample(replay_buffer, batch_size)\n","                states, actions, rewards, next_states, dones = zip(*batch)\n","\n","                # Convert to tensor and move to device\n","                states = torch.tensor(states, dtype=torch.float, device=device)\n","                actions = torch.tensor(actions, dtype=torch.long, device=device)\n","                rewards = torch.tensor(rewards, dtype=torch.float, device=device)\n","                next_states = torch.tensor(next_states, dtype=torch.float, device=device)\n","                dones = torch.tensor(dones, dtype=torch.float, device=device)\n","\n","                # Compute Q-value and target Q-value\n","                current_q_values = policy_net(states).gather(1, actions.unsqueeze(1))\n","                next_q_values = target_net(next_states).max(1)[0].detach()\n","                target_q_values = rewards + gamma * next_q_values * (1 - dones)\n","\n","                # Compute loss and update policy network\n","                loss = criterion(current_q_values, target_q_values.unsqueeze(1))\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()\n","\n","                # Update target network periodically\n","                step_count += 1\n","                if step_count % target_update_frequency == 0:\n","                    target_net.load_state_dict(policy_net.state_dict())\n","\n","        print(f\"Episode: {episode}, Total Reward: {total_reward}\")\n","\n","# Train the agent\n","# train(num_episodes=1000)\n","train(num_episodes=100)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8e98mp6h3_Fj","executionInfo":{"status":"ok","timestamp":1741003533678,"user_tz":-330,"elapsed":7010,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"315ef61f-9c3b-4a29-a94a-6b81054da050"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Episode: 0, Total Reward: 9.0\n","Episode: 1, Total Reward: 12.0\n","Episode: 2, Total Reward: 10.0\n","Episode: 3, Total Reward: 9.0\n","Episode: 4, Total Reward: 9.0\n","Episode: 5, Total Reward: 10.0\n","Episode: 6, Total Reward: 10.0\n","Episode: 7, Total Reward: 9.0\n","Episode: 8, Total Reward: 10.0\n","Episode: 9, Total Reward: 10.0\n","Episode: 10, Total Reward: 11.0\n","Episode: 11, Total Reward: 9.0\n","Episode: 12, Total Reward: 8.0\n","Episode: 13, Total Reward: 10.0\n","Episode: 14, Total Reward: 10.0\n","Episode: 15, Total Reward: 10.0\n","Episode: 16, Total Reward: 9.0\n","Episode: 17, Total Reward: 10.0\n","Episode: 18, Total Reward: 9.0\n","Episode: 19, Total Reward: 9.0\n","Episode: 20, Total Reward: 10.0\n","Episode: 21, Total Reward: 10.0\n","Episode: 22, Total Reward: 10.0\n","Episode: 23, Total Reward: 9.0\n","Episode: 24, Total Reward: 10.0\n","Episode: 25, Total Reward: 9.0\n","Episode: 26, Total Reward: 10.0\n","Episode: 27, Total Reward: 9.0\n","Episode: 28, Total Reward: 8.0\n","Episode: 29, Total Reward: 10.0\n","Episode: 30, Total Reward: 11.0\n","Episode: 31, Total Reward: 24.0\n","Episode: 32, Total Reward: 10.0\n","Episode: 33, Total Reward: 12.0\n","Episode: 34, Total Reward: 12.0\n","Episode: 35, Total Reward: 12.0\n","Episode: 36, Total Reward: 10.0\n","Episode: 37, Total Reward: 11.0\n","Episode: 38, Total Reward: 13.0\n","Episode: 39, Total Reward: 11.0\n","Episode: 40, Total Reward: 9.0\n","Episode: 41, Total Reward: 12.0\n","Episode: 42, Total Reward: 10.0\n","Episode: 43, Total Reward: 9.0\n","Episode: 44, Total Reward: 16.0\n","Episode: 45, Total Reward: 28.0\n","Episode: 46, Total Reward: 12.0\n","Episode: 47, Total Reward: 10.0\n","Episode: 48, Total Reward: 12.0\n","Episode: 49, Total Reward: 11.0\n","Episode: 50, Total Reward: 9.0\n","Episode: 51, Total Reward: 9.0\n","Episode: 52, Total Reward: 10.0\n","Episode: 53, Total Reward: 15.0\n","Episode: 54, Total Reward: 10.0\n","Episode: 55, Total Reward: 10.0\n","Episode: 56, Total Reward: 9.0\n","Episode: 57, Total Reward: 10.0\n","Episode: 58, Total Reward: 10.0\n","Episode: 59, Total Reward: 10.0\n","Episode: 60, Total Reward: 9.0\n","Episode: 61, Total Reward: 9.0\n","Episode: 62, Total Reward: 10.0\n","Episode: 63, Total Reward: 10.0\n","Episode: 64, Total Reward: 11.0\n","Episode: 65, Total Reward: 11.0\n","Episode: 66, Total Reward: 13.0\n","Episode: 67, Total Reward: 10.0\n","Episode: 68, Total Reward: 9.0\n","Episode: 69, Total Reward: 10.0\n","Episode: 70, Total Reward: 8.0\n","Episode: 71, Total Reward: 11.0\n","Episode: 72, Total Reward: 18.0\n","Episode: 73, Total Reward: 16.0\n","Episode: 74, Total Reward: 24.0\n","Episode: 75, Total Reward: 15.0\n","Episode: 76, Total Reward: 21.0\n","Episode: 77, Total Reward: 11.0\n","Episode: 78, Total Reward: 18.0\n","Episode: 79, Total Reward: 34.0\n","Episode: 80, Total Reward: 22.0\n","Episode: 81, Total Reward: 16.0\n","Episode: 82, Total Reward: 15.0\n","Episode: 83, Total Reward: 31.0\n","Episode: 84, Total Reward: 57.0\n","Episode: 85, Total Reward: 15.0\n","Episode: 86, Total Reward: 50.0\n","Episode: 87, Total Reward: 43.0\n","Episode: 88, Total Reward: 17.0\n","Episode: 89, Total Reward: 33.0\n","Episode: 90, Total Reward: 31.0\n","Episode: 91, Total Reward: 39.0\n","Episode: 92, Total Reward: 71.0\n","Episode: 93, Total Reward: 24.0\n","Episode: 94, Total Reward: 33.0\n","Episode: 95, Total Reward: 44.0\n","Episode: 96, Total Reward: 70.0\n","Episode: 97, Total Reward: 66.0\n","Episode: 98, Total Reward: 81.0\n","Episode: 99, Total Reward: 46.0\n"]}]},{"cell_type":"markdown","source":["## Policy Gradient Methods\n","Policy Gradient Methods are a class of reinforcement learning algorithms that learn a policy directly by optimizing the parameters of a policy network. Instead of learning Q-values like Q-Learning or DQN, policy gradient methods focus on finding the optimal action-selection strategy that maximizes cumulative rewards. A popular approach is the REINFORCE algorithm, where actions are sampled from a policy distribution, and the policy is updated using gradients based on rewards."],"metadata":{"id":"6kXnFDx95gaN"}},{"cell_type":"code","source":["# Import necessary libraries\n","import gym\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","\n","# Create the Policy Network:\n","class PolicyNetwork(tf.keras.Model):\n","    def __init__(self, action_space):\n","        super(PolicyNetwork, self).__init__()\n","        self.d1 = layers.Dense(24, activation='relu')\n","        self.d2 = layers.Dense(24, activation='relu')\n","        self.out = layers.Dense(action_space, activation='softmax')\n","\n","    def call(self, state):\n","        x = self.d1(state)\n","        x = self.d2(x)\n","        return self.out(x)\n","\n","# Train the Policy Network:\n","\n","def train(env, policy, optimizer, episodes=1000, gamma=0.99):\n","    for episode in range(episodes):\n","        state = env.reset()\n","        state = np.reshape(state, [1, env.observation_space.shape[0]])\n","        rewards = []\n","        actions = []\n","        states = []\n","        total_reward = 0\n","\n","        while True:\n","            action_probs = policy(state).numpy()\n","            action = np.random.choice(env.action_space.n, p=action_probs[0])\n","            next_state, reward, done, _ = env.step(action)\n","            next_state = np.reshape(next_state, [1, env.observation_space.shape[0]])\n","\n","            states.append(state)\n","            actions.append(action)\n","            rewards.append(reward)\n","            state = next_state\n","            total_reward += reward\n","\n","            if done:\n","                discounted_rewards = []\n","                sum_rewards = 0\n","                for r in reversed(rewards):\n","                    sum_rewards = r + gamma * sum_rewards\n","                    discounted_rewards.insert(0, sum_rewards)\n","\n","                discounted_rewards = np.array(discounted_rewards)\n","                discounted_rewards = (discounted_rewards - np.mean(discounted_rewards)) / (np.std(discounted_rewards) + 1e-10)\n","\n","                with tf.GradientTape() as tape:\n","                    logits = policy(tf.concat(states, axis=0))\n","                    indices = np.array([[i, a] for i, a in enumerate(actions)])\n","                    action_probs = tf.gather_nd(logits, indices)\n","                    loss = -tf.reduce_mean(tf.math.log(action_probs) * discounted_rewards)\n","\n","                grads = tape.gradient(loss, policy.trainable_variables)\n","                optimizer.apply_gradients(zip(grads, policy.trainable_variables))\n","\n","                print(f'Episode: {episode+1}, Total Reward: {total_reward}')\n","                break\n","\n","env = gym.make('CartPole-v1')\n","policy = PolicyNetwork(env.action_space.n)\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","episodes=100\n","gamma=0.99\n","\n","train(env, policy, optimizer, episodes, gamma)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lje3Dpy44i6p","executionInfo":{"status":"ok","timestamp":1741003876742,"user_tz":-330,"elapsed":22396,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"c83b27c8-ea4c-4c33-aa74-d3c0b3a8a4ce"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.11/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.11/dist-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n","  if not isinstance(terminated, (bool, np.bool8)):\n"]},{"output_type":"stream","name":"stdout","text":["Episode: 1, Total Reward: 14.0\n","Episode: 2, Total Reward: 25.0\n","Episode: 3, Total Reward: 13.0\n","Episode: 4, Total Reward: 42.0\n","Episode: 5, Total Reward: 26.0\n","Episode: 6, Total Reward: 29.0\n","Episode: 7, Total Reward: 9.0\n","Episode: 8, Total Reward: 27.0\n","Episode: 9, Total Reward: 12.0\n","Episode: 10, Total Reward: 13.0\n","Episode: 11, Total Reward: 36.0\n","Episode: 12, Total Reward: 62.0\n","Episode: 13, Total Reward: 11.0\n","Episode: 14, Total Reward: 36.0\n","Episode: 15, Total Reward: 12.0\n","Episode: 16, Total Reward: 11.0\n","Episode: 17, Total Reward: 17.0\n","Episode: 18, Total Reward: 47.0\n","Episode: 19, Total Reward: 21.0\n","Episode: 20, Total Reward: 21.0\n","Episode: 21, Total Reward: 30.0\n","Episode: 22, Total Reward: 16.0\n","Episode: 23, Total Reward: 15.0\n","Episode: 24, Total Reward: 20.0\n","Episode: 25, Total Reward: 34.0\n","Episode: 26, Total Reward: 12.0\n","Episode: 27, Total Reward: 18.0\n","Episode: 28, Total Reward: 23.0\n","Episode: 29, Total Reward: 13.0\n","Episode: 30, Total Reward: 34.0\n","Episode: 31, Total Reward: 19.0\n","Episode: 32, Total Reward: 19.0\n","Episode: 33, Total Reward: 32.0\n","Episode: 34, Total Reward: 63.0\n","Episode: 35, Total Reward: 16.0\n","Episode: 36, Total Reward: 14.0\n","Episode: 37, Total Reward: 12.0\n","Episode: 38, Total Reward: 18.0\n","Episode: 39, Total Reward: 12.0\n","Episode: 40, Total Reward: 16.0\n","Episode: 41, Total Reward: 17.0\n","Episode: 42, Total Reward: 12.0\n","Episode: 43, Total Reward: 12.0\n","Episode: 44, Total Reward: 9.0\n","Episode: 45, Total Reward: 14.0\n","Episode: 46, Total Reward: 24.0\n","Episode: 47, Total Reward: 28.0\n","Episode: 48, Total Reward: 43.0\n","Episode: 49, Total Reward: 20.0\n","Episode: 50, Total Reward: 25.0\n","Episode: 51, Total Reward: 16.0\n","Episode: 52, Total Reward: 26.0\n","Episode: 53, Total Reward: 45.0\n","Episode: 54, Total Reward: 11.0\n","Episode: 55, Total Reward: 29.0\n","Episode: 56, Total Reward: 33.0\n","Episode: 57, Total Reward: 19.0\n","Episode: 58, Total Reward: 17.0\n","Episode: 59, Total Reward: 33.0\n","Episode: 60, Total Reward: 13.0\n","Episode: 61, Total Reward: 38.0\n","Episode: 62, Total Reward: 24.0\n","Episode: 63, Total Reward: 19.0\n","Episode: 64, Total Reward: 20.0\n","Episode: 65, Total Reward: 18.0\n","Episode: 66, Total Reward: 45.0\n","Episode: 67, Total Reward: 24.0\n","Episode: 68, Total Reward: 30.0\n","Episode: 69, Total Reward: 53.0\n","Episode: 70, Total Reward: 24.0\n","Episode: 71, Total Reward: 13.0\n","Episode: 72, Total Reward: 9.0\n","Episode: 73, Total Reward: 12.0\n","Episode: 74, Total Reward: 16.0\n","Episode: 75, Total Reward: 10.0\n","Episode: 76, Total Reward: 18.0\n","Episode: 77, Total Reward: 28.0\n","Episode: 78, Total Reward: 23.0\n","Episode: 79, Total Reward: 30.0\n","Episode: 80, Total Reward: 31.0\n","Episode: 81, Total Reward: 26.0\n","Episode: 82, Total Reward: 34.0\n","Episode: 83, Total Reward: 20.0\n","Episode: 84, Total Reward: 26.0\n","Episode: 85, Total Reward: 14.0\n","Episode: 86, Total Reward: 14.0\n","Episode: 87, Total Reward: 41.0\n","Episode: 88, Total Reward: 21.0\n","Episode: 89, Total Reward: 22.0\n","Episode: 90, Total Reward: 13.0\n","Episode: 91, Total Reward: 10.0\n","Episode: 92, Total Reward: 14.0\n","Episode: 93, Total Reward: 49.0\n","Episode: 94, Total Reward: 40.0\n","Episode: 95, Total Reward: 57.0\n","Episode: 96, Total Reward: 16.0\n","Episode: 97, Total Reward: 36.0\n","Episode: 98, Total Reward: 52.0\n","Episode: 99, Total Reward: 49.0\n","Episode: 100, Total Reward: 13.0\n"]}]},{"cell_type":"markdown","source":["## one-Class SVM\n","One-Class SVM (Support Vector Machine) is an algorithm for anomaly detection that identifies data points that differ significantly from the normal distribution of data. It's particularly useful when the dataset primarily consists of one class, and we want to detect outliers. One-Class SVM separates the data into a high-density region (normal data) and sparse regions (anomalies)."],"metadata":{"id":"ElbpEZW94tk1"}},{"cell_type":"code","source":["# Import necessary libraries\n","from sklearn.svm import OneClassSVM\n","import numpy as np\n","\n","# Sample data (normal data points clustered around 0)\n","X= 0.3 * np.random.randn(100, 2)\n","X_train= np.r_[X + 2, X - 2] # Create a dataset with points around two clusters\n","\n","# New test data including some outliers\n","X_test= np.r_[X + 2, X - 2, np.random.uniform(low= -6, high= 6, size= (20, 2))]\n","\n","# Initialize and train the model\n","model= OneClassSVM(gamma= 'auto', nu= 0.1)\n","model.fit(X_train)\n","\n","# Predict on test data (-1 indicates as anomaly, 1 indicates normal)\n","predictions= model.predict(X_test)\n","\n","# Display prediction\n","print(\"Predictions: \", predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wWru3ey56pDj","executionInfo":{"status":"ok","timestamp":1741020725421,"user_tz":-330,"elapsed":62,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"6895ff84-cf9e-42a9-8571-84c052733c8e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Predictions:  [ 1  1  1  1  1  1 -1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1 -1\n","  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1\n"," -1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1\n","  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1 -1  1  1  1  1\n","  1  1  1 -1  1  1  1  1  1  1 -1  1  1  1  1  1  1 -1  1  1  1 -1  1  1\n","  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n","  1  1  1 -1 -1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1\n","  1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1 -1\n","  1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n"," -1 -1 -1 -1]\n"]}]},{"cell_type":"markdown","source":["## Isolation Forest\n","Isolation Forest is an ensemble method for anomaly detection that isolates anomalies rather than profiling normal data. The algorithm randomly selects a feature and a split value to partition the data, creating trees where anomalies are easier to isolate due to their sparse distribution. Anomalies are identified based on their shorter path lengths in the tree structure, as they are isolated faster than normal points."],"metadata":{"id":"dVyNX3IE7CZ3"}},{"cell_type":"code","source":["# Import necessary libraries\n","from sklearn.ensemble import IsolationForest\n","import numpy as np\n","\n","# Sample data (normal data points clustered around 0)\n","X= 0.3 * np.random.randn(100, 2)\n","X_train= np.r_[X + 2, X - 2] # Create a dataset with points around two clusters\n","\n","# New test data including some outliers\n","X_test= np.r_[X + 2, X - 2, np.random.uniform(low= -6, high= 6, size= (20, 2))]\n","\n","# Initialize and train the model\n","model= IsolationForest(contamination= 0.1, random_state= 42)\n","model.fit(X_train)\n","\n","# Predict on test data (-1 indicates as anomaly, 1 indicates normal)\n","predictions= model.predict(X_test)\n","\n","# Display prediction\n","print(\"Predictions: \", predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NtI-4Bq57KA7","executionInfo":{"status":"ok","timestamp":1741020975171,"user_tz":-330,"elapsed":435,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"372ae589-d8cb-4a7d-d38e-4e2ed303e174"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Predictions:  [ 1  1  1  1  1 -1  1 -1  1 -1  1  1  1  1  1 -1  1  1  1  1  1  1  1 -1\n","  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1\n","  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1 -1\n","  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n","  1  1  1  1  1  1  1  1  1 -1  1 -1  1 -1  1  1  1  1  1 -1  1  1  1  1\n","  1  1  1 -1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n"," -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1\n","  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n","  1 -1  1  1  1  1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n"," -1 -1 -1 -1]\n"]}]},{"cell_type":"markdown","source":["## Convolutional Neural Networks (CNNs)\n","Convolutional Neural Networks (CNNs) are deep learning models specifically designed for processing structured grid data, such as images. CNNs use convolutional layers that apply filters to the input image, capturing spatial hierarchies and features like edges, textures, and shapes. CNNs are widely used in computer vision tasks like image classification, object detection, and segmentation."],"metadata":{"id":"oLpq5tGT8B8r"}},{"cell_type":"code","source":["# Import necessary libraries\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.datasets import mnist\n","\n","# Load and preprocess the MNIST dataset\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","X_train, X_test = X_train / 255.0, X_test / 255.0  # Normalize the pixel values\n","X_train = X_train.reshape(-1, 28, 28, 1)  # Reshape for CNN\n","X_test = X_test.reshape(-1, 28, 28, 1)\n","\n","# Define the CNN model\n","model = models.Sequential([\n","    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","    layers.Flatten(),  # Correct this layer\n","    layers.Dense(64, activation='relu'),  # Change Conv2D to Dense\n","    layers.Dense(10, activation='softmax')  # Change Conv2D to Dense for output layer\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n","\n","# Evaluate the model\n","test_loss, test_acc = model.evaluate(X_test, y_test)\n","print(\"Test Accuracy: \", test_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"th4tA-R-6_58","executionInfo":{"status":"ok","timestamp":1741022123368,"user_tz":-330,"elapsed":369114,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"0920a887-af96-494e-9cb0-d1b14bb4b0d3"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 71ms/step - accuracy: 0.8413 - loss: 0.4978 - val_accuracy: 0.9787 - val_loss: 0.0726\n","Epoch 2/5\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 76ms/step - accuracy: 0.9814 - loss: 0.0607 - val_accuracy: 0.9834 - val_loss: 0.0553\n","Epoch 3/5\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 77ms/step - accuracy: 0.9868 - loss: 0.0412 - val_accuracy: 0.9870 - val_loss: 0.0441\n","Epoch 4/5\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 82ms/step - accuracy: 0.9906 - loss: 0.0303 - val_accuracy: 0.9875 - val_loss: 0.0429\n","Epoch 5/5\n","\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 74ms/step - accuracy: 0.9924 - loss: 0.0231 - val_accuracy: 0.9890 - val_loss: 0.0414\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9877 - loss: 0.0373\n","Test Accuracy:  0.9904000163078308\n"]}]},{"cell_type":"markdown","source":["## Recurrent Neural Networks (RNNs)\n","Recurrent Neural Networks (RNNs) are neural networks designed for sequential data, such as time series, language, or speech. RNNs have connections that form cycles, allowing them to retain information from previous steps in the sequence. This makes RNNs well-suited for tasks like text generation, language modeling, and time series forecasting. A common variant, Long Short-Term Memory (LSTM), helps to address the issue of long-term dependency."],"metadata":{"id":"0RYGikxh-_pg"}},{"cell_type":"code","source":["# Import necessary libraries\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.datasets import imdb\n","from tensorflow.keras.preprocessing import sequence\n","\n","# Load and preprocess the IMDB dataset\n","max_features= 10000 # Vocalubary size\n","max_len= 500\n","\n","(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words= max_features)\n","X_train= sequence.pad_sequences(X_train, maxlen= max_len)\n","X_test= sequence.pad_sequences(X_test, maxlen= max_len)\n","\n","# Define the RNN model\n","model= models.Sequential([\n","    layers.Embedding(max_features, 32, input_length= max_len),\n","    layers.SimpleRNN(32),\n","    layers.Dense(1, activation='sigmoid')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n","\n","# Evaluate the model\n","test_loss, test_acc = model.evaluate(X_test, y_test)\n","print(\"Test Accuracy: \", test_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IXc1lczj-sE5","executionInfo":{"status":"ok","timestamp":1741022493857,"user_tz":-330,"elapsed":231516,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"cf75787a-aa5d-4014-d34d-4e30a2beae24"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 130ms/step - accuracy: 0.6064 - loss: 0.6525 - val_accuracy: 0.8066 - val_loss: 0.4515\n","Epoch 2/5\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 129ms/step - accuracy: 0.8464 - loss: 0.3653 - val_accuracy: 0.8432 - val_loss: 0.3861\n","Epoch 3/5\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 130ms/step - accuracy: 0.8884 - loss: 0.2863 - val_accuracy: 0.8174 - val_loss: 0.4393\n","Epoch 4/5\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 127ms/step - accuracy: 0.9392 - loss: 0.1682 - val_accuracy: 0.8268 - val_loss: 0.4491\n","Epoch 5/5\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 129ms/step - accuracy: 0.9815 - loss: 0.0670 - val_accuracy: 0.8222 - val_loss: 0.5362\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.8169 - loss: 0.5390\n","Test Accuracy:  0.8146399855613708\n"]}]},{"cell_type":"markdown","source":["## Long Short-Term Memory (LSTM)\n","Long Short-Term Memory (LSTM) networks are a type of RNN specifically designed to capture long-term dependencies in sequential data. LSTMs use gating mechanisms to control the flow of information, which helps prevent the vanishing gradient problem that standard RNNs suffer from. They are commonly used in tasks like language modeling, machine translation, and time series prediction."],"metadata":{"id":"vQ0pZ51LA-oP"}},{"cell_type":"code","source":["# Import necessary libraries\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.datasets import imdb\n","from tensorflow.keras.preprocessing import sequence\n","\n","# Load and preprocess the IMDB dataset\n","max_features= 10000 # Vocalubary size\n","max_len= 500\n","\n","(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words= max_features)\n","X_train= sequence.pad_sequences(X_train, maxlen= max_len)\n","X_test= sequence.pad_sequences(X_test, maxlen= max_len)\n","\n","# Define the RNN model\n","model= models.Sequential([\n","    layers.Embedding(max_features, 32, input_length= max_len),\n","    layers.LSTM(32),\n","    layers.Dense(1, activation='sigmoid')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n","\n","# Evaluate the model\n","test_loss, test_acc = model.evaluate(X_test, y_test)\n","print(\"Test Accuracy: \", test_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sHAfTyEZAqTM","executionInfo":{"status":"ok","timestamp":1741022920851,"user_tz":-330,"elapsed":426510,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"ac3cca96-82ce-460f-970e-0dd522643b47"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 244ms/step - accuracy: 0.6809 - loss: 0.5701 - val_accuracy: 0.8680 - val_loss: 0.3299\n","Epoch 2/5\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 227ms/step - accuracy: 0.9069 - loss: 0.2459 - val_accuracy: 0.8672 - val_loss: 0.3306\n","Epoch 3/5\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 227ms/step - accuracy: 0.9358 - loss: 0.1788 - val_accuracy: 0.8786 - val_loss: 0.3213\n","Epoch 4/5\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 228ms/step - accuracy: 0.9533 - loss: 0.1343 - val_accuracy: 0.8754 - val_loss: 0.3260\n","Epoch 5/5\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 250ms/step - accuracy: 0.9564 - loss: 0.1226 - val_accuracy: 0.8748 - val_loss: 0.3997\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.8678 - loss: 0.4205\n","Test Accuracy:  0.8660799860954285\n"]}]},{"cell_type":"markdown","source":["## Transformers\n","Transformers are deep learning architectures designed for handling sequential data without relying on recurrence, which is commonly used in RNNs. Instead, Transformers use a mechanism called self-attention to process all tokens in the sequence simultaneously, capturing dependencies between tokens regardless of their distance in the sequence.\n","\n","Transformers have become the foundation of many NLP tasks and models, including BERT and GPT."],"metadata":{"id":"7YqYDfTBBZK2"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.datasets import imdb\n","from tensorflow.keras.preprocessing import sequence\n","\n","# Load and preprocess the IMDB dataset\n","max_features = 10000  # Vocabulary size\n","max_len = 200\n","\n","(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n","X_train = sequence.pad_sequences(X_train, maxlen=max_len)\n","X_test = sequence.pad_sequences(X_test, maxlen=max_len)\n","\n","# Define the Transformer block\n","class TransformerBlock(layers.Layer):\n","    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n","        super(TransformerBlock, self).__init__()\n","        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","        self.ffn = tf.keras.Sequential([\n","            layers.Dense(ff_dim, activation='relu'),\n","            layers.Dense(embed_dim)\n","        ])\n","        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = layers.Dropout(rate)\n","        self.dropout2 = layers.Dropout(rate)\n","\n","    def call(self, inputs, training=None):\n","        attn_output = self.att(inputs, inputs)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(inputs + attn_output)\n","\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","\n","        return self.layernorm2(out1 + ffn_output)\n","\n","# Define the model with an embedding layer, transformer block, and output layers\n","embed_dim = 32\n","num_heads = 2\n","ff_dim = 32\n","\n","inputs = layers.Input(shape=(max_len,))\n","embedding_layer = layers.Embedding(input_dim=max_features, output_dim=embed_dim, input_length=max_len)\n","\n","x = embedding_layer(inputs)\n","transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim, rate=0.1)\n","x = transformer_block(x, training=True) # Explicitily pass `training= True`\n","x = layers.GlobalAveragePooling1D()(x)\n","x = layers.Dropout(0.1)(x)\n","x = layers.Dense(20, activation=\"relu\")(x)\n","x = layers.Dropout(0.1)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","\n","model = tf.keras.Model(inputs=inputs, outputs=outputs)\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X_train, y_train, epochs=3, batch_size=64, validation_split=0.2)\n","\n","# Evaluate the model\n","test_loss, test_acc = model.evaluate(X_test, y_test)\n","print(\"Test Accuracy:\", test_acc)"],"metadata":{"id":"IPI3Ptx7D1B-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741024124720,"user_tz":-330,"elapsed":270273,"user":{"displayName":"Turk Pasha","userId":"14654520425428926420"}},"outputId":"db46672f-0116-4855-a646-5c586e94b506"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 199ms/step - accuracy: 0.6458 - loss: 0.5903 - val_accuracy: 0.8724 - val_loss: 0.3029\n","Epoch 2/3\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 180ms/step - accuracy: 0.9030 - loss: 0.2512 - val_accuracy: 0.8792 - val_loss: 0.2826\n","Epoch 3/3\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 178ms/step - accuracy: 0.9438 - loss: 0.1620 - val_accuracy: 0.8776 - val_loss: 0.3024\n","\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 34ms/step - accuracy: 0.8662 - loss: 0.3202\n","Test Accuracy: 0.8640000224113464\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"LaEBn09MG725"},"execution_count":null,"outputs":[]}]}