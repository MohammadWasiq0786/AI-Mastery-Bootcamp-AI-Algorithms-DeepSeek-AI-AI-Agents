{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP5MgaY/wiGR9BYLgO4uFoM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Course Name: **AI Mastery Bootcamp: AI Algorithms, DeepSeek AI, AI Agents**\n","\n","# Section 17: **Intermediate TensorFlow**"],"metadata":{"id":"67X3evAx5ERq"}},{"cell_type":"markdown","source":["## Customizing Models with Keras\n","### Introduction to Keras API\n","  * **Overview of Keras API**\n","    * High-Level API\n","    * Modularity\n","    * Compatibility\n","  \n","  * Key Components of Keras API\n","    * Layers\n","    * Activations\n","    * Loss Functions\n","    * Optimizers\n","    * Metrics\n","    * Callbacks"],"metadata":{"id":"_LtSIzVtzMVc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"a5GOfscW5C30"},"outputs":[],"source":["# 1. Introduction to Keras API\n","## 1.1. Example of Building a Neural Network with Keras\n","import tensorflow as tf\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Flatten, Dense\n","\n","# Define the model architecture\n","model = Sequential([\n","    Flatten(input_shape=(28, 28)),  # Input layer (flatten 28-28 images)\n","    Dense(128, activation='relu'),  # Hidden layer with 128 neurons and ReLU actiation\n","    Dense(10, activation='softmax') # Output layer with 10 neurons (for 10 classes) and softmax activation\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Print the model summary\n","model.summary()\n","\n","## 1.2. Train the model\n","model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(val_images, val_labels))\n","\n","## 1.3. Evaluate the model\n","loss, accuracy = model.evaluate(test_images, test_labels)\n","print(f\"Test Loss: {loss}\")\n","print(f'Test accuracy: {accuracy}')\n","\n","## 1.4. Make prediction\n","predictions= model.predict(test_images)"]},{"cell_type":"code","source":["# Model Architecture (Sequential Model)\n","import tensorflow as tf\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n","\n","## Define a Sequential Model\n","model = Sequential([\n","    Conv2D(32, kernel_size= (3, 3), activation='relu', input_shape=(28, 28, 1)),\n","    MaxPooling2D(pool_size= (2, 2)),\n","    Conv2D(64, kernel_size= (3, 3), activation='relu'),\n","    MaxPooling2D(pool_size= (2, 2)),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dense(10, activation='softmax')\n","])\n","\n","## Compile the model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","## Print the model summary\n","model.summary()"],"metadata":{"id":"2uikZq_y5IUo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model Architecture (Functional API)\n","import tensorflow as tf\n","from tensorflow.keras import Sequential, Model\n","from tensorflow.keras.layers import Input, Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n","\n","## Define input layer\n","inputs = Input(shape=(28, 28, 1))\n","\n","## Define convolutional layers\n","conv1 = Conv2D(32, kernel_size= (3, 3), activation='relu')(inputs)\n","pool1= MaxPooling2D(pool_size= (2, 2))(conv1)\n","conv2= Conv2D(64, kernel_size= (3, 3), activation='relu')(pool1)\n","pool2= MaxPooling2D(pool_size= (2, 2))(conv2)\n","\n","## Flaten Layer\n","flatten= Flatten()(pool2)\n","\n","## Dense Layers\n","dense1= Dense(128, activation='relu')(flatten)\n","outputs= Dense(10, activation='softmax')(dense1)\n","\n","## Create the model\n","model= Model(inputs=inputs, outputs=outputs)\n","\n","## Compile the model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","## Print the model summary\n","model.summary()"],"metadata":{"id":"8TIm6XPH2jOH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Building complex models with Keras\n","* Multiple Inputs and Outputs\n","* Shared Layers\n","* Custom Layers and Loss Functions\n","* Model Subclassing"],"metadata":{"id":"brYVzY_Qn5Ti"}},{"cell_type":"markdown","source":["## Training and evaluating models\n","### Data Preparation"],"metadata":{"id":"jB-CZkz5oGMV"}},{"cell_type":"code","source":["## 1. Data Preparation\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","import matplotlib.pyplot as plt\n","\n","\n","# Load and preprocess the MNIST dataset\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","X_train= X_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n","X_test= X_test.reshape(-1, 28, 28, 1).astype('float32') / 2\n","y_train= to_categorical(y_train, num_classes=10)\n","y_test= to_categorical(y_test, num_classes=10)\n","\n","# Split the data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n","\n","## 2. Define the simple convolutional neural network Model\n","\n","model= Sequential([\n","    Conv2D(32, kernel_size= (3, 3), activation='relu', input_shape=(28, 28, 1)),\n","    MaxPooling2D(pool_size= (2, 2)),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dense(10, activation='softmax')\n","])\n","\n","## 3. Compile the Model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","## 4. Train the Model\n","history= model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_val, y_val))\n","\n","## 5. Evaluate the Model\n","test_loss, test_accuracy = model.evaluate(X_test, y_test)\n","print(f\"Test Loss: {test_loss}\")\n","print(f\"Test Accuracy: {test_accuracy}\")\n","\n","## 6. Visualize Training History\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","## 7. Make Predictions\n","predictions= model.predict(X_test)"],"metadata":{"id":"oyGIT9hZ2jT0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Convolutional Neural Networks (CNNs)\n","### Introduction to CNNs\n","* Basic Concepts of CNNs\n","  * Convolutional Layers\n","  * Pooling Layers\n","  * Activation Functions\n","  * Fully Connected Layers\n","* Convolution Operation\n","* Convolutional Layer\n","* Pooling Operation\n","* Architecture of CNNs\n","* Training CNNs\n","* Transfer Learning\n","* Applications of CNNs"],"metadata":{"id":"B-qs2xb8qRo3"}},{"cell_type":"code","source":["## 1. Import TensorFlow and Keras\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","import matplotlib.pyplot as plt\n","\n","\n","## 2. Load and preprocess the MNIST dataset\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","X_train= X_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n","X_test= X_test.reshape(-1, 28, 28, 1).astype('float32') / 2\n","y_train= to_categorical(y_train, num_classes=10)\n","y_test= to_categorical(y_test, num_classes=10)\n","\n","# Split the data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n","\n","## 3. Define the Model Architecture\n","model= Sequential([\n","    Conv2D(32, kernel_size= (3, 3), activation='relu', input_shape=(28, 28, 1)),\n","    MaxPooling2D(pool_size= (2, 2)),\n","    Conv2D(64, kernel_size= (3, 3), activation='relu'),\n","    MaxPooling2D(pool_size= (2, 2)),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dense(10, activation='softmax')\n","])\n","\n","## 4. Compile the Model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","## 5. Train the Model\n","history= model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_val, y_val))\n","\n","## 6. Evaluate the Model\n","test_loss, test_accuracy = model.evaluate(X_test, y_test)\n","print(f\"Test Loss: {test_loss}\")\n","print(f\"Test Accuracy: {test_accuracy}\")\n","\n","## 7. Visualize Training History\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","## 8. Make Predictions\n","predictions= model.predict(X_test)"],"metadata":{"id":"P0aRzP--2jWt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Transfer Learning with Pre-trained CNNs\n","* Overview of Transfer Learning\n","* Benefits of Transfer Learning\n","  * Improved Performance\n","  * Faster Training\n","  * Robustness\n","* Transfer Learning Strategies\n","  * Feature Extraction\n","  * Fine-Tuning"],"metadata":{"id":"VPmlvyo2r2Qg"}},{"cell_type":"code","source":["# Implementing Transfer Learning with TensorFlow/Keras\n","## 1. Load Pre-trained Model\n","base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","## 2. Feature Extraction\n","base_model.trainable = False\n","model= Sequential([\n","    base_model,\n","    Flatten(),\n","    Dense(256, activation='relu'),\n","    Dense(1, activation='sigmoid')\n","])\n","\n","## 3. Fine Tuning\n","base_model.trainable = True\n","fine_tune_at= 100\n","\n","for layer in base_model.layers[:fine_tune_at]:\n","  layer.trainable= False\n","\n","## 4. Compile and Train the Model\n","model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","## 5. Train\n","model.fit(train_dataset, epochs= 10, validation_data= val_dataset)\n","\n","## 6. Evaluate the Model\n","test_loss, test_accuracy = model.evaluate(X_test, y_test)\n","print(f\"Test Loss: {test_loss}\")\n","print(f\"Test Accuracy: {test_accuracy}\")"],"metadata":{"id":"PYt2_RS8k7Hv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Recurrent Neural Networks (RNNs)\n","### Introduction to RNNs\n","* Basic Concepts of RNNs\n","  * Sequential Data\n","  * Temporal Dependency\n","  * Vanishing Gradient Problem\n","* Architecture of RNNs\n","  * Recurrent Connections\n","  * Hidden State\n","  * Output\n","* Types of RNNs\n","  * One-to-One\n","  * One-to-Many\n","  * Many-to-One\n","  * Many-to-Many (Sequence-to-Sequence)\n","* Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRUs)\n","  * LSTM\n","  * GRU\n","* Training RNNs\n","  * Backpropagation Through Time (BPTT)\n","  * Gradient Clipping\n","  * Regularization\n","* Applications of RNNs\n","  * Natural Language Processing\n","  * Speech Recognition\n","  * Time Series Analysis"],"metadata":{"id":"ATHzcoTfttO6"}},{"cell_type":"code","source":["# Building and Training RNNs with TensorFlow\n","\n","## 1. Import TensorFlow and Keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Dense\n","\n","## 2. Define the Model Architecture\n","### 2.1. Simple RNNs\n","model= Sequential([\n","    SimpleRNN(units=62, input_shape=(sequence_length, input_dim), activation='relu'),\n","    Dense(num_classes, activation='softmax')\n","])\n","\n","### 2.2. LSTM\n","model= Sequential([\n","    LSTM(units=62, input_shape=(sequence_length, input_dim), activation='relu'),\n","    Dense(num_classes, activation='softmax')\n","])\n","\n","### 2.3. GRU\n","model= Sequential([\n","    GRU(units=62, input_shape=(sequence_length, input_dim), activation='relu'),\n","    Dense(num_classes, activation='softmax')\n","])\n","\n","## 3. Compile the Model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","## 4. TLoad and Preprocess Data\n","X_train, y_train = load_data(train_data_path)\n","X_test, y_test = load_data(test_data_path)\n","\n","## 5. Train the Model\n","model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n","\n","## 6. Evaluate the Model\n","test_loss, test_accuracy = model.evaluate(X_test, y_test)\n","print(f\"Test Loss: {test_loss}\")\n","print(f\"Test Accuracy: {test_accuracy}\")"],"metadata":{"id":"Pv9wfan-ttnd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Applications of RNNs\n","* Language Modeling\n","  * Text Generation\n","  * Machine Translation\n","  * Speech Recognition\n","  * Sentiment Analysis\n","* Time Series Prediction\n","  * Stock Market Prediction\n","  * Weather Forecasting\n","  * Demand Forecasting\n","  * Healthcare Forecasting"],"metadata":{"id":"OD7deMKkwjah"}}]}